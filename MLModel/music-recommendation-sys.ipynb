{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1770108,"sourceType":"datasetVersion","datasetId":1052176}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openl3 librosa sentence-transformers annoy faiss-cpu ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T14:25:10.827654Z","iopub.execute_input":"2025-06-15T14:25:10.828048Z","iopub.status.idle":"2025-06-15T14:27:01.842793Z","shell.execute_reply.started":"2025-06-15T14:25:10.828013Z","shell.execute_reply":"2025-06-15T14:27:01.842044Z"}},"outputs":[{"name":"stdout","text":"Collecting openl3\n  Using cached openl3-0.4.2.tar.gz (29 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: annoy in /usr/local/lib/python3.11/dist-packages (1.17.3)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openl3) (2.18.0)\nRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from openl3) (1.26.4)\nRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from openl3) (1.15.2)\nCollecting kapre>=0.3.5 (from openl3)\n  Downloading kapre-0.3.7.tar.gz (26 kB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: soundfile>=0.9.0.post1 in /usr/local/lib/python3.11/dist-packages (from openl3) (0.13.1)\nCollecting resampy<0.3.0,>=0.2.1 (from openl3)\n  Downloading resampy-0.2.2.tar.gz (323 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.4/323.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from openl3) (3.13.0)\nRequirement already satisfied: moviepy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from openl3) (1.0.3)\nRequirement already satisfied: scikit-image>=0.14.3 in /usr/local/lib/python3.11/dist-packages (from openl3) (0.25.2)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\nRequirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.0->openl3) (0.1.11)\nRequirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.0->openl3) (2.37.0)\nRequirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.0->openl3) (0.6.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->openl3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->openl3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->openl3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->openl3) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->openl3) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->openl3) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\nRequirement already satisfied: six>=1.3 in /usr/local/lib/python3.11/dist-packages (from resampy<0.3.0,>=0.2.1->openl3) (1.17.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.3->openl3) (3.4.2)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.3->openl3) (2025.3.30)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.9.0.post1->openl3) (1.17.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (75.2.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (3.0.1)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (3.8.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.0.0->openl3) (0.37.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->openl3) (0.45.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.9.0.post1->openl3) (2.22)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.0.0->openl3) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.0.0->openl3) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.0.0->openl3) (0.14.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.0.0->openl3) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.0.0->openl3) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.0.0->openl3) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.0->openl3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.0->openl3) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.13.0->openl3) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.13.0->openl3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.13.0->openl3) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.0.0->openl3) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.0.0->openl3) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.0.0->openl3) (0.1.2)\nDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openl3, kapre, resampy\n  Building wheel for openl3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openl3: filename=openl3-0.4.2-py2.py3-none-any.whl size=249327030 sha256=f849f802924ca57c8926da557de018c1bccaac359e949ec5d895ba0abedaa36e\n  Stored in directory: /root/.cache/pip/wheels/35/e9/4c/b1e39385b21f2b4d70c01b8793ecc921d69f167cc772868abe\n  Building wheel for kapre (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for kapre: filename=kapre-0.3.7-py3-none-any.whl size=29642 sha256=8741418b2d513cbec02744b3f86d6ebd9a9fee359aee65417d93c4ff98c52b08\n  Stored in directory: /root/.cache/pip/wheels/d2/17/ce/09b7d799a7c8b463b0a1657941331e0f10112864ff78d28f87\n  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320705 sha256=b0134d1fb395afa797e2d0f672f58343e3d1cb70a5b8f2124bda838ed7be4524\n  Stored in directory: /root/.cache/pip/wheels/0f/df/63/a2209e98c9b8599049252b409794538bff2aa0d37b5e71fab6\nSuccessfully built openl3 kapre resampy\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, resampy, kapre, openl3, faiss-cpu\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed faiss-cpu-1.11.0 kapre-0.3.7 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openl3-0.4.2 resampy-0.2.2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Define the file path (assuming the file is now accessible or uploaded)\nfile_path = '/kaggle/input/spotify-12m-songs/tracks_features.csv'\n\ntry:\n    # Load the dataset into a pandas DataFrame\n    df = pd.read_csv(file_path)\n\n    print(\"Dataset loaded successfully!\\n\")\n\n    # Display the first 5 rows of the DataFrame\n    print(\"First 5 rows of the dataset:\")\n    print(df.head())\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Display a concise summary of the DataFrame, including data types and non-null values\n    print(\"Information about the dataset:\")\n    df.info()\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Display basic descriptive statistics for numerical columns\n    print(\"Descriptive statistics of the dataset:\")\n    print(df.describe())\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Check for the number of unique values in each column\n    print(\"Number of unique values in each column:\")\n    print(df.nunique())\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n    # Check for missing values\n    print(\"Missing values in each column:\")\n    print(df.isnull().sum())\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at '{file_path}'.\")\n    print(\"Please make sure the file is in the correct directory or has been uploaded.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T17:13:33.778082Z","iopub.execute_input":"2025-06-16T17:13:33.778619Z","iopub.status.idle":"2025-06-16T17:13:46.584028Z","shell.execute_reply.started":"2025-06-16T17:13:33.778595Z","shell.execute_reply":"2025-06-16T17:13:46.583265Z"}},"outputs":[{"name":"stdout","text":"Dataset loaded successfully!\n\nFirst 5 rows of the dataset:\n                       id                   name                      album  \\\n0  7lmeHLHBe4nmXzuXc0HDjk                Testify  The Battle Of Los Angeles   \n1  1wsRitfRRtWyEapl0q22o8        Guerrilla Radio  The Battle Of Los Angeles   \n2  1hR0fIFK2qRG3f3RF70pb7       Calm Like a Bomb  The Battle Of Los Angeles   \n3  2lbASgTSoDO7MTuLAXlTW0              Mic Check  The Battle Of Los Angeles   \n4  1MQTmpYOZ6fcMQc56Hdo7T  Sleep Now In the Fire  The Battle Of Los Angeles   \n\n                 album_id                       artists  \\\n0  2eia0myWFgoHuttJytCxgX  ['Rage Against The Machine']   \n1  2eia0myWFgoHuttJytCxgX  ['Rage Against The Machine']   \n2  2eia0myWFgoHuttJytCxgX  ['Rage Against The Machine']   \n3  2eia0myWFgoHuttJytCxgX  ['Rage Against The Machine']   \n4  2eia0myWFgoHuttJytCxgX  ['Rage Against The Machine']   \n\n                   artist_ids  track_number  disc_number  explicit  \\\n0  ['2d0hyoQ5ynDBnkvAbJKORj']             1            1     False   \n1  ['2d0hyoQ5ynDBnkvAbJKORj']             2            1      True   \n2  ['2d0hyoQ5ynDBnkvAbJKORj']             3            1     False   \n3  ['2d0hyoQ5ynDBnkvAbJKORj']             4            1      True   \n4  ['2d0hyoQ5ynDBnkvAbJKORj']             5            1     False   \n\n   danceability  ...  speechiness  acousticness  instrumentalness  liveness  \\\n0         0.470  ...       0.0727       0.02610          0.000011    0.3560   \n1         0.599  ...       0.1880       0.01290          0.000071    0.1550   \n2         0.315  ...       0.4830       0.02340          0.000002    0.1220   \n3         0.440  ...       0.2370       0.16300          0.000004    0.1210   \n4         0.426  ...       0.0701       0.00162          0.105000    0.0789   \n\n   valence    tempo  duration_ms  time_signature  year  release_date  \n0    0.503  117.906       210133             4.0  1999    1999-11-02  \n1    0.489  103.680       206200             4.0  1999    1999-11-02  \n2    0.370  149.749       298893             4.0  1999    1999-11-02  \n3    0.574   96.752       213640             4.0  1999    1999-11-02  \n4    0.539  127.059       205600             4.0  1999    1999-11-02  \n\n[5 rows x 24 columns]\n\n==================================================\n\nInformation about the dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1204025 entries, 0 to 1204024\nData columns (total 24 columns):\n #   Column            Non-Null Count    Dtype  \n---  ------            --------------    -----  \n 0   id                1204025 non-null  object \n 1   name              1204022 non-null  object \n 2   album             1204014 non-null  object \n 3   album_id          1204025 non-null  object \n 4   artists           1204025 non-null  object \n 5   artist_ids        1204025 non-null  object \n 6   track_number      1204025 non-null  int64  \n 7   disc_number       1204025 non-null  int64  \n 8   explicit          1204025 non-null  bool   \n 9   danceability      1204025 non-null  float64\n 10  energy            1204025 non-null  float64\n 11  key               1204025 non-null  int64  \n 12  loudness          1204025 non-null  float64\n 13  mode              1204025 non-null  int64  \n 14  speechiness       1204025 non-null  float64\n 15  acousticness      1204025 non-null  float64\n 16  instrumentalness  1204025 non-null  float64\n 17  liveness          1204025 non-null  float64\n 18  valence           1204025 non-null  float64\n 19  tempo             1204025 non-null  float64\n 20  duration_ms       1204025 non-null  int64  \n 21  time_signature    1204025 non-null  float64\n 22  year              1204025 non-null  int64  \n 23  release_date      1204025 non-null  object \ndtypes: bool(1), float64(10), int64(6), object(7)\nmemory usage: 212.4+ MB\n\n==================================================\n\nDescriptive statistics of the dataset:\n       track_number   disc_number  danceability        energy           key  \\\ncount  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06   \nmean   7.656352e+00  1.055906e+00  4.930565e-01  5.095363e-01  5.194151e+00   \nstd    5.994977e+00  2.953752e-01  1.896694e-01  2.946839e-01  3.536731e+00   \nmin    1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%    3.000000e+00  1.000000e+00  3.560000e-01  2.520000e-01  2.000000e+00   \n50%    7.000000e+00  1.000000e+00  5.010000e-01  5.240000e-01  5.000000e+00   \n75%    1.000000e+01  1.000000e+00  6.330000e-01  7.660000e-01  8.000000e+00   \nmax    5.000000e+01  1.300000e+01  1.000000e+00  1.000000e+00  1.100000e+01   \n\n           loudness          mode   speechiness  acousticness  \\\ncount  1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06   \nmean  -1.180870e+01  6.714595e-01  8.438219e-02  4.467511e-01   \nstd    6.982132e+00  4.696827e-01  1.159914e-01  3.852014e-01   \nmin   -6.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n25%   -1.525400e+01  0.000000e+00  3.510000e-02  3.760000e-02   \n50%   -9.791000e+00  1.000000e+00  4.460000e-02  3.890000e-01   \n75%   -6.717000e+00  1.000000e+00  7.230000e-02  8.610000e-01   \nmax    7.234000e+00  1.000000e+00  9.690000e-01  9.960000e-01   \n\n       instrumentalness      liveness       valence         tempo  \\\ncount      1.204025e+06  1.204025e+06  1.204025e+06  1.204025e+06   \nmean       2.828605e-01  2.015994e-01  4.279866e-01  1.176344e+02   \nstd        3.762844e-01  1.804591e-01  2.704846e-01  3.093705e+01   \nmin        0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%        7.600000e-06  9.680000e-02  1.910000e-01  9.405400e+01   \n50%        8.080000e-03  1.250000e-01  4.030000e-01  1.167260e+02   \n75%        7.190000e-01  2.450000e-01  6.440000e-01  1.370460e+02   \nmax        1.000000e+00  1.000000e+00  1.000000e+00  2.489340e+02   \n\n        duration_ms  time_signature          year  \ncount  1.204025e+06    1.204025e+06  1.204025e+06  \nmean   2.488399e+05    3.832494e+00  2.007328e+03  \nstd    1.622104e+05    5.611826e-01  1.210117e+01  \nmin    1.000000e+03    0.000000e+00  0.000000e+00  \n25%    1.740900e+05    4.000000e+00  2.002000e+03  \n50%    2.243390e+05    4.000000e+00  2.009000e+03  \n75%    2.858400e+05    4.000000e+00  2.015000e+03  \nmax    6.061090e+06    5.000000e+00  2.020000e+03  \n\n==================================================\n\nNumber of unique values in each column:\nid                  1204025\nname                 850943\nalbum                106161\nalbum_id             118382\nartists              165365\nartist_ids           166423\ntrack_number             50\ndisc_number              13\nexplicit                  2\ndanceability           1362\nenergy                 3441\nkey                      12\nloudness              39805\nmode                      2\nspeechiness            1653\nacousticness           5398\ninstrumentalness       5402\nliveness               1799\nvalence                1884\ntempo                140472\nduration_ms          210013\ntime_signature            5\nyear                    101\nrelease_date          10566\ndtype: int64\n\n==================================================\n\nMissing values in each column:\nid                   0\nname                 3\nalbum               11\nalbum_id             0\nartists              0\nartist_ids           0\ntrack_number         0\ndisc_number          0\nexplicit             0\ndanceability         0\nenergy               0\nkey                  0\nloudness             0\nmode                 0\nspeechiness          0\nacousticness         0\ninstrumentalness     0\nliveness             0\nvalence              0\ntempo                0\nduration_ms          0\ntime_signature       0\nyear                 0\nrelease_date         0\ndtype: int64\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install DNN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T14:55:42.886953Z","iopub.execute_input":"2025-06-15T14:55:42.887625Z","iopub.status.idle":"2025-06-15T14:55:55.455804Z","shell.execute_reply.started":"2025-06-15T14:55:42.887591Z","shell.execute_reply":"2025-06-15T14:55:55.454976Z"}},"outputs":[{"name":"stdout","text":"Collecting DNN\n  Downloading dnn-0.7.5-py3-none-any.whl.metadata (1.7 kB)\nCollecting rs4 (from DNN)\n  Downloading rs4-0.3.31-py3-none-any.whl.metadata (832 bytes)\nCollecting tfserver (from DNN)\n  Downloading tfserver-0.4.11-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from DNN) (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from DNN) (1.2.2)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from DNN) (1.0.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from DNN) (3.4.2)\nRequirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (from DNN) (0.2.7)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from DNN) (3.20.3)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from DNN) (0.3.8)\nCollecting webrtcvad (from DNN)\n  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting exif (from DNN)\n  Downloading exif-1.6.1-py3-none-any.whl.metadata (5.2 kB)\nCollecting fdet (from DNN)\n  Downloading fdet-0.2.1-py3-none-any.whl.metadata (10 kB)\nCollecting plum-py<2.0.0,>=0.5.0 (from exif->DNN)\n  Downloading plum_py-0.8.7-py3-none-any.whl.metadata (1.5 kB)\nCollecting ttictoc (from fdet->DNN)\n  Downloading ttictoc-0.5.6-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from fdet->DNN) (4.11.0.86)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from fdet->DNN) (8.1.8)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fdet->DNN) (4.67.1)\nRequirement already satisfied: colour in /usr/local/lib/python3.11/dist-packages (from fdet->DNN) (0.1.5)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from fdet->DNN) (0.4.6)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt->DNN) (1.15.2)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt->DNN) (1.17.0)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt->DNN) (3.1.1)\nRequirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt->DNN) (0.10.9.7)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->DNN) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->DNN) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->DNN) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->DNN) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->DNN) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->DNN) (2.4.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from rs4->DNN) (7.0.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from rs4->DNN) (2.32.3)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from rs4->DNN) (1.3.5)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->DNN) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->DNN) (3.6.0)\nCollecting atila (from tfserver->DNN)\n  Downloading atila-0.27.0-py3-none-any.whl.metadata (16 kB)\nCollecting skitai>=0.57.0 (from atila->tfserver->DNN)\n  Downloading skitai-0.57.1-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->DNN) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->DNN) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->DNN) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->DNN) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->rs4->DNN) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->rs4->DNN) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->rs4->DNN) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->rs4->DNN) (2025.4.26)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->DNN) (2024.2.0)\nCollecting sqlphile>=0.9 (from skitai>=0.57.0->atila->tfserver->DNN)\n  Downloading sqlphile-0.9.7-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: h2>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from skitai>=0.57.0->atila->tfserver->DNN) (4.2.0)\nRequirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2>=4.0.0->skitai>=0.57.0->atila->tfserver->DNN) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2>=4.0.0->skitai>=0.57.0->atila->tfserver->DNN) (4.1.0)\nDownloading dnn-0.7.5-py3-none-any.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading exif-1.6.1-py3-none-any.whl (30 kB)\nDownloading fdet-0.2.1-py3-none-any.whl (25 kB)\nDownloading rs4-0.3.31-py3-none-any.whl (632 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.1/632.1 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tfserver-0.4.11-py3-none-any.whl (27 kB)\nDownloading plum_py-0.8.7-py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading atila-0.27.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ttictoc-0.5.6-py3-none-any.whl (5.7 kB)\nDownloading skitai-0.57.1-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sqlphile-0.9.7-py3-none-any.whl (27 kB)\nBuilding wheels for collected packages: webrtcvad\n  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73506 sha256=09d4347c7a73dca2c4de515ffd49b3985aaee7de797dfa41ddc597e685c58f84\n  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\nSuccessfully built webrtcvad\nInstalling collected packages: webrtcvad, ttictoc, plum-py, rs4, exif, sqlphile, skitai, atila, tfserver, fdet, DNN\nSuccessfully installed DNN-0.7.5 atila-0.27.0 exif-1.6.1 fdet-0.2.1 plum-py-0.8.7 rs4-0.3.31 skitai-0.57.1 sqlphile-0.9.7 tfserver-0.4.11 ttictoc-0.5.6 webrtcvad-2.0.10\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import silhouette_score, calinski_harabasz_score\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, r2_score, classification_report, accuracy_score\nimport umap\nfrom scipy import stats\nfrom scipy.spatial.distance import cosine, euclidean\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\nimport joblib\nimport pickle\nimport os\nfrom pathlib import Path\nimport json\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nimport multiprocessing as mp\nimport sqlite3\nfrom collections import defaultdict, deque\nfrom datetime import datetime, timedelta\nimport hashlib\n\n# Optional libraries with proper error handling\ntry:\n    from annoy import AnnoyIndex\n    ANNOY_AVAILABLE = True\nexcept ImportError:\n    ANNOY_AVAILABLE = False\n\ntry:\n    import tensorflow as tf\n    \n    # Complete T4 GPU utilization with corrected configuration\n    physical_devices = tf.config.list_physical_devices('GPU')\n    if physical_devices:\n        print(f\"Found {len(physical_devices)} GPU(s)\")\n        try:\n            # Option 1: Use memory growth (recommended for most cases)\n            for gpu in physical_devices:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            print(\"GPU memory growth enabled\")\n            \n            # Option 2: Use virtual devices with memory limit (alternative)\n            # Uncomment the lines below and comment out the memory growth section above if you prefer this approach\n            # for gpu in physical_devices:\n            #     tf.config.experimental.set_virtual_device_configuration(\n            #         gpu,\n            #         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=14000)]\n            #     )\n            # print(\"GPU virtual devices configured with memory limit\")\n            \n        except RuntimeError as e:\n            print(f\"GPU configuration must be set before GPUs have been initialized: {e}\")\n            print(\"Continuing with default GPU settings\")\n    else:\n        print(\"No GPU found, using CPU\")\n    \n    # Enable mixed precision for faster training (only if GPU available)\n    if physical_devices:\n        try:\n            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n            print(\"Mixed precision enabled\")\n        except Exception as e:\n            print(f\"Mixed precision not supported: {e}\")\n    \n    # Configure for maximum performance\n    tf.config.threading.set_inter_op_parallelism_threads(0)  # Use all available cores\n    tf.config.threading.set_intra_op_parallelism_threads(0)  # Use all available cores\n    \n    from tensorflow.keras.models import Model, load_model\n    from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n    from tensorflow.keras.optimizers import Adam\n    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n    TF_AVAILABLE = True\n    print(\"TensorFlow configured successfully\")\n    \nexcept (ImportError, Exception) as e:\n    print(f\"TensorFlow not available or initialization failed: {e}\")\n    TF_AVAILABLE = False\n    \nclass ModelManager:\n    def __init__(self, base_path=\"./models\"):\n        self.base_path = Path(base_path)\n        self.base_path.mkdir(exist_ok=True)\n        \n    def save_model(self, model, model_name, model_type=\"sklearn\"):\n        \"\"\"Save model with metadata\"\"\"\n        model_dir = self.base_path / model_name\n        model_dir.mkdir(exist_ok=True)\n        \n        timestamp = int(time.time())\n        \n        if model_type == \"tensorflow\":\n            model_path = model_dir / f\"{model_name}_{timestamp}.h5\"\n            model.save(str(model_path))\n        elif model_type == \"sklearn\":\n            model_path = model_dir / f\"{model_name}_{timestamp}.joblib\"\n            joblib.dump(model, model_path)\n        else:\n            model_path = model_dir / f\"{model_name}_{timestamp}.pkl\"\n            with open(model_path, 'wb') as f:\n                pickle.dump(model, f)\n        \n        # Save metadata\n        metadata = {\n            \"model_name\": model_name,\n            \"model_type\": model_type,\n            \"timestamp\": timestamp,\n            \"file_path\": str(model_path)\n        }\n        \n        with open(model_dir / \"metadata.json\", 'w') as f:\n            json.dump(metadata, f, indent=2)\n        \n        print(f\"Model saved: {model_path}\")\n        return str(model_path)\n    \n    def load_model(self, model_name, model_type=\"sklearn\"):\n        \"\"\"Load the latest model\"\"\"\n        model_dir = self.base_path / model_name\n        \n        if not model_dir.exists():\n            raise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n        \n        # Find latest model\n        if model_type == \"tensorflow\":\n            model_files = list(model_dir.glob(\"*.h5\"))\n        elif model_type == \"sklearn\":\n            model_files = list(model_dir.glob(\"*.joblib\"))\n        else:\n            model_files = list(model_dir.glob(\"*.pkl\"))\n        \n        if not model_files:\n            raise FileNotFoundError(f\"No model files found in {model_dir}\")\n        \n        latest_model = max(model_files, key=lambda x: x.stat().st_mtime)\n        \n        if model_type == \"tensorflow\":\n            return load_model(str(latest_model))\n        elif model_type == \"sklearn\":\n            return joblib.load(latest_model)\n        else:\n            with open(latest_model, 'rb') as f:\n                return pickle.load(f)\n\nclass AdvancedMusicRecommender:\n    def __init__(self, df, test_size=0.2, random_state=42, n_jobs=-1):\n        self.df = df.copy()\n        self.test_size = test_size\n        self.random_state = random_state\n        self.n_jobs = n_jobs if n_jobs != -1 else mp.cpu_count()\n    \n        # Initialize model manager\n        self.model_manager = ModelManager()\n    \n        # Initialize components\n        self.scaler = StandardScaler()\n        self.pca = None\n        self.umap_model = None\n        self.kmeans = None\n        self.dbscan = None\n    \n        # Embeddings\n        self.audio_features = None\n        self.metadata_features = None\n        self.combined_embeddings = None\n        self.deep_embeddings = None\n    \n        # Models\n        self.autoencoder = None\n        self.popularity_predictor = None\n        self.nearest_neighbors = None\n        self.annoy_index = None\n        \n        # Results\n        self.dimensionality_results = {}\n        self.recommendation_cache = {}\n        \n        # Features\n        self.audio_cols = ['danceability', 'energy', 'loudness', 'speechiness',\n                          'acousticness', 'instrumentalness', 'liveness', 'valence',\n                          'tempo', 'duration_ms']\n        \n        self._preprocess_data()    \n    def _preprocess_data(self):\n        print(\"Preprocessing data...\")\n        # Handle missing values\n        self.df = self.df.dropna(subset=self.audio_cols)\n        \n        # Feature engineering\n        self._create_derived_features()\n        self._encode_categorical()\n        self._create_targets()\n        \n        print(f\"Dataset shape: {self.df.shape}\")\n        \n    def _analyze_clusters(self):\n        \"\"\"Analyze cluster characteristics\"\"\"\n        if 'kmeans_cluster' not in self.df.columns:\n            return\n        \n        print(\"\\nCluster Analysis:\")\n        for cluster_id in sorted(self.df['kmeans_cluster'].unique()):\n            cluster_data = self.df[self.df['kmeans_cluster'] == cluster_id]\n            print(f\"\\nCluster {cluster_id} ({len(cluster_data)} songs):\")\n            \n            # Analyze audio features\n            for feature in ['energy', 'valence', 'danceability', 'acousticness']:\n                if feature in cluster_data.columns:\n                    mean_val = cluster_data[feature].mean()\n                    print(f\"  Avg {feature}: {mean_val:.3f}\")\n    \n    def _create_derived_features(self):\n        # Energy-based features\n        self.df['energy_valence_ratio'] = self.df['energy'] / (self.df['valence'] + 0.001)\n        self.df['danceability_energy_product'] = self.df['danceability'] * self.df['energy']\n        \n        # Categories\n        self.df['tempo_category'] = pd.cut(self.df['tempo'], \n                                         bins=[0, 90, 120, 140, 200], \n                                         labels=['slow', 'moderate', 'fast', 'very_fast'])\n        \n        self.df['duration_category'] = pd.cut(self.df['duration_ms'], \n                                            bins=[0, 180000, 240000, 300000, float('inf')], \n                                            labels=['short', 'medium', 'long', 'very_long'])\n        \n        # Mood classification\n        self.df['mood'] = 'neutral'\n        conditions = [\n            (self.df['valence'] > 0.6) & (self.df['energy'] > 0.6),\n            (self.df['valence'] > 0.6) & (self.df['energy'] <= 0.6),\n            (self.df['valence'] <= 0.4) & (self.df['energy'] > 0.6),\n            (self.df['valence'] <= 0.4) & (self.df['energy'] <= 0.4)\n        ]\n        choices = ['happy_energetic', 'happy_calm', 'sad_energetic', 'sad_calm']\n        self.df['mood'] = np.select(conditions, choices, default='neutral')\n        \n        # Additional features\n        self.df['acoustic_electronic_balance'] = self.df['acousticness'] - self.df['energy']\n        self.df['vocal_prominence'] = 1 - self.df['instrumentalness']\n        self.df['audio_complexity'] = (self.df['speechiness'] + \n                                     self.df['instrumentalness'] + \n                                     self.df['liveness']) / 3\n    \n    def _encode_categorical(self):\n        if 'explicit' in self.df.columns:\n            self.df['explicit'] = self.df['explicit'].astype(int)\n        \n        categorical_cols = ['time_signature', 'tempo_category', 'duration_category', 'mood']\n        self.encoders = {}\n        encoded_features = []\n        \n        for col in categorical_cols:\n            if col in self.df.columns:\n                encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n                encoded = encoder.fit_transform(self.df[[col]])\n                col_names = [f\"{col}_{cat}\" for cat in encoder.categories_[0]]\n                encoded_df = pd.DataFrame(encoded, columns=col_names, index=self.df.index)\n                encoded_features.append(encoded_df)\n                self.encoders[col] = encoder\n        \n        self.metadata_features = pd.concat(encoded_features, axis=1) if encoded_features else pd.DataFrame(index=self.df.index)\n    \n    def _create_targets(self):\n        if 'popularity' in self.df.columns:\n            self.df['popularity_score'] = self.df['popularity']\n        else:\n            # Synthetic popularity score\n            self.df['popularity_score'] = (0.3 * self.df['danceability'] +\n                                         0.2 * self.df['energy'] +\n                                         0.2 * self.df['valence'] +\n                                         0.1 * (1 - self.df['acousticness']) +\n                                         0.1 * self.df['loudness'] / self.df['loudness'].max() +\n                                         0.1 * np.random.random(len(self.df)))\n    \n    def create_embeddings(self):\n        print(\"Creating embeddings...\")\n        \n        # Audio features\n        audio_data = self.df[self.audio_cols + ['energy_valence_ratio', 'danceability_energy_product',\n                                              'acoustic_electronic_balance', 'vocal_prominence', 'audio_complexity']]\n        self.audio_features = self.scaler.fit_transform(audio_data)\n        \n        # Combine with metadata\n        if not self.metadata_features.empty:\n            explicit_data = self.df[['explicit']].values if 'explicit' in self.df.columns else np.array([]).reshape(len(self.df), 0)\n            if explicit_data.size > 0:\n                metadata_combined = np.hstack([explicit_data, self.metadata_features.values])\n            else:\n                metadata_combined = self.metadata_features.values\n            self.combined_embeddings = np.hstack([self.audio_features, metadata_combined])\n        else:\n            self.combined_embeddings = self.audio_features\n        \n        print(f\"Combined embeddings shape: {self.combined_embeddings.shape}\")\n        \n        # Deep embeddings with error handling\n        if TF_AVAILABLE:\n            try:\n                self._create_deep_embeddings()\n            except Exception as e:\n                print(f\"Deep embeddings failed: {e}. Using combined embeddings.\")\n                self.deep_embeddings = None\n    def save_complete_system(self, system_name=\"music_recommender_system\"):\n            \"\"\"Save the complete recommendation system\"\"\"\n            print(\"Saving complete system...\")\n            \n            system_dir = self.model_manager.base_path / system_name\n            system_dir.mkdir(exist_ok=True)\n            \n            # Save all components\n            components = {\n                'scaler': self.scaler,\n                'audio_features': self.audio_features,\n                'metadata_features': self.metadata_features,\n                'combined_embeddings': self.combined_embeddings,\n                'deep_embeddings': self.deep_embeddings,\n                'dimensionality_results': self.dimensionality_results,\n                'audio_cols': self.audio_cols,\n                'encoders': getattr(self, 'encoders', {})\n            }\n            \n            # Save components\n            for name, component in components.items():\n                if component is not None:\n                    if name in ['audio_features', 'metadata_features', 'combined_embeddings', 'deep_embeddings']:\n                        np.save(system_dir / f\"{name}.npy\", component)\n                    else:\n                        joblib.dump(component, system_dir / f\"{name}.joblib\")\n            \n            # Save DataFrame (sample for web use)\n            sample_df = self.df.sample(min(1000, len(self.df)), random_state=42)\n            sample_df.to_csv(system_dir / \"sample_data.csv\", index=False)\n            \n            # Save system metadata\n            metadata = {\n                \"system_name\": system_name,\n                \"timestamp\": int(time.time()),\n                \"data_shape\": self.df.shape,\n                \"embedding_dim\": self.combined_embeddings.shape[1] if self.combined_embeddings is not None else None,\n                \"deep_embedding_dim\": self.deep_embeddings.shape[1] if self.deep_embeddings is not None else None,\n                \"models_saved\": [\"autoencoder\", \"encoder\", \"kmeans_model\", \"dbscan_model\", \"pca_model\", \"umap_model\", \"popularity_predictor\"]\n            }\n            \n            with open(system_dir / \"system_metadata.json\", 'w') as f:\n                json.dump(metadata, f, indent=2)\n            \n            print(f\"Complete system saved to: {system_dir}\")\n            return str(system_dir)\n    \n    def _create_deep_embeddings(self):\n        print(\"Creating deep embeddings with GPU optimization...\")\n        \n        X_train, X_val = train_test_split(self.combined_embeddings, test_size=0.2, random_state=self.random_state)\n        \n        input_dim = self.combined_embeddings.shape[1]\n        encoding_dim = min(128, input_dim // 2)  # Increased for better capacity\n        \n        # Optimized autoencoder architecture\n        with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):\n            input_layer = Input(shape=(input_dim,))\n            \n            # Encoder with larger capacity\n            encoded = Dense(256, activation='relu')(input_layer)\n            encoded = BatchNormalization()(encoded)\n            encoded = Dropout(0.3)(encoded)\n            \n            encoded = Dense(128, activation='relu')(encoded)\n            encoded = BatchNormalization()(encoded)\n            encoded = Dropout(0.2)(encoded)\n            \n            encoded = Dense(encoding_dim, activation='relu', name='encoded')(encoded)\n            \n            # Decoder\n            decoded = Dense(128, activation='relu')(encoded)\n            decoded = BatchNormalization()(decoded)\n            decoded = Dropout(0.2)(decoded)\n            \n            decoded = Dense(256, activation='relu')(decoded)\n            decoded = BatchNormalization()(decoded)\n            decoded = Dropout(0.3)(decoded)\n            \n            decoded = Dense(input_dim, activation='linear')(decoded)\n            \n            self.autoencoder = Model(input_layer, decoded)\n            encoder = Model(input_layer, encoded)\n        \n        # Optimized compilation for mixed precision\n        optimizer = Adam(learning_rate=0.001)\n        self.autoencoder.compile(\n            optimizer=optimizer, \n            loss='mse',\n            metrics=['mae']\n        )\n        \n        # Enhanced callbacks with model saving\n        model_checkpoint = ModelCheckpoint(\n            'best_autoencoder.h5',\n            monitor='val_loss',\n            save_best_only=True,\n            save_weights_only=False\n        )\n        \n        callbacks = [\n            EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n            ReduceLROnPlateau(patience=7, factor=0.5, min_lr=1e-7),\n            model_checkpoint\n        ]\n        \n        # Train with larger batch size for GPU efficiency\n        batch_size = 128 if len(X_train) > 1000 else 64\n        \n        # FIXED: Removed use_multiprocessing and workers parameters\n        history = self.autoencoder.fit(\n            X_train, X_train, \n            epochs=100,  # Increased epochs\n            batch_size=batch_size,\n            validation_data=(X_val, X_val), \n            callbacks=callbacks, \n            verbose=1\n            # Removed: use_multiprocessing=True, workers=self.n_jobs\n        )\n        \n        # Generate embeddings - FIXED: Removed use_multiprocessing and workers parameters\n        self.deep_embeddings = encoder.predict(\n            self.combined_embeddings, \n            batch_size=batch_size,\n            verbose=1\n            # Removed: use_multiprocessing=True, workers=self.n_jobs\n        )\n        \n        # Save models\n        self.model_manager.save_model(self.autoencoder, \"autoencoder\", \"tensorflow\")\n        self.model_manager.save_model(encoder, \"encoder\", \"tensorflow\")\n        \n        print(f\"Deep embeddings shape: {self.deep_embeddings.shape}\")\n        return history\n    \n    def perform_clustering(self, n_clusters=8, sample_size=2000):\n        \"\"\"Optimized clustering with sampling for speed\"\"\"\n        print(\"Performing optimized clustering...\")\n        \n        embeddings = self.deep_embeddings if self.deep_embeddings is not None else self.combined_embeddings\n        \n        # Sample data for faster clustering if dataset is large\n        if len(embeddings) > sample_size:\n            sample_idx = np.random.choice(len(embeddings), sample_size, replace=False)\n            sample_embeddings = embeddings[sample_idx]\n            print(f\"Using sample of {sample_size} songs for clustering\")\n        else:\n            sample_embeddings = embeddings\n            sample_idx = np.arange(len(embeddings))\n        \n        # Fast K-means with fewer iterations\n        self.kmeans = KMeans(n_clusters=n_clusters, random_state=self.random_state, \n                            n_init=3, max_iter=100)\n        sample_labels = self.kmeans.fit_predict(sample_embeddings)\n        \n        # Predict labels for full dataset\n        if len(embeddings) > sample_size:\n            all_labels = self.kmeans.predict(embeddings)\n        else:\n            all_labels = sample_labels\n        \n        self.df['kmeans_cluster'] = all_labels\n        \n        # Skip DBSCAN for speed (optional, can add back if needed)\n        self.df['dbscan_cluster'] = -1  # Placeholder\n        \n        # Quick evaluation\n        if len(np.unique(all_labels)) > 1:\n            sample_silhouette = silhouette_score(sample_embeddings, sample_labels)\n            print(f\"K-means Silhouette (sample): {sample_silhouette:.3f}\")\n        \n        self._analyze_clusters()\n        \n    def dimensionality_reduction(self, n_samples=5000):  # Increased sample size\n        print(\"Performing dimensionality reduction with parallel processing...\")\n        \n        if len(self.df) > n_samples:\n            sample_idx = np.random.choice(len(self.df), n_samples, replace=False)\n            embeddings_sample = self.combined_embeddings[sample_idx]\n            df_sample = self.df.iloc[sample_idx].copy()\n        else:\n            embeddings_sample = self.combined_embeddings\n            df_sample = self.df.copy()\n            sample_idx = np.arange(len(self.df))\n        \n        def run_pca():\n            pca = PCA(n_components=2, random_state=self.random_state)\n            return pca.fit_transform(embeddings_sample), pca\n        \n        def run_umap():\n            umap_model = umap.UMAP(\n                n_components=2, \n                random_state=self.random_state, \n                n_neighbors=15,\n                n_jobs=self.n_jobs\n            )\n            return umap_model.fit_transform(embeddings_sample), umap_model\n        \n        def run_tsne():\n            tsne = TSNE(\n                n_components=2, \n                random_state=self.random_state, \n                perplexity=30,\n                n_jobs=self.n_jobs\n            )\n            return tsne.fit_transform(embeddings_sample), tsne\n        \n        # Run in parallel\n        with ThreadPoolExecutor(max_workers=3) as executor:\n            pca_future = executor.submit(run_pca)\n            umap_future = executor.submit(run_umap)\n            tsne_future = executor.submit(run_tsne)\n            \n            pca_result, self.pca = pca_future.result()\n            umap_result, self.umap_model = umap_future.result()\n            tsne_result, tsne_model = tsne_future.result()\n        \n        # Save dimensionality reduction models\n        self.model_manager.save_model(self.pca, \"pca_model\", \"sklearn\")\n        self.model_manager.save_model(self.umap_model, \"umap_model\", \"sklearn\")\n        \n        self.dimensionality_results = {\n            'pca': pca_result, 'umap': umap_result, 'tsne': tsne_result,\n            'sample_idx': sample_idx, 'df_sample': df_sample\n        }\n        \n        print(f\"PCA explained variance: {self.pca.explained_variance_ratio_.sum():.3f}\")\n    \n    def build_recommendation_system(self):\n        print(\"Building recommendation system...\")\n        \n        embeddings = self.deep_embeddings if self.deep_embeddings is not None else self.combined_embeddings\n        \n        # Nearest neighbors\n        self.nearest_neighbors = NearestNeighbors(n_neighbors=50, metric='cosine')\n        self.nearest_neighbors.fit(embeddings)\n        \n        # Annoy index\n        if ANNOY_AVAILABLE:\n            self.annoy_index = AnnoyIndex(embeddings.shape[1], metric='angular')\n            for i, v in enumerate(embeddings):\n                self.annoy_index.add_item(i, v)\n            self.annoy_index.build(n_trees=20)\n        \n        # Popularity predictor\n        self._train_popularity_predictor()\n    \n    def _train_popularity_predictor(self):\n        print(\"Training popularity predictor with optimization...\")\n        \n        # Use deep embeddings if available, otherwise use combined embeddings\n        X = self.deep_embeddings if self.deep_embeddings is not None else self.combined_embeddings\n        y = self.df['popularity_score'].values\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n        \n        # Optimized RandomForest with more trees and parallel processing\n        self.popularity_predictor = RandomForestRegressor(\n            n_estimators=200,  # Increased\n            max_depth=15,\n            min_samples_split=5,\n            min_samples_leaf=2,\n            random_state=self.random_state, \n            n_jobs=self.n_jobs,\n            verbose=1\n        )\n        \n        self.popularity_predictor.fit(X_train, y_train)\n        \n        # Save the model\n        self.model_manager.save_model(self.popularity_predictor, \"popularity_predictor\", \"sklearn\")\n        \n        y_pred = self.popularity_predictor.predict(X_test)\n        mse = mean_squared_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n        \n        print(f\"Popularity Predictor - MSE: {mse:.3f}, R²: {r2:.3f}\")\n\n\n    def get_recommendations(self, song_idx, n_recommendations=10, method='hybrid'):\n        if song_idx >= len(self.df):\n            raise ValueError(f\"Song index {song_idx} out of range\")\n        \n        cache_key = f\"{song_idx}_{n_recommendations}_{method}\"\n        if cache_key in self.recommendation_cache:\n            return self.recommendation_cache[cache_key]\n        \n        embeddings = self.deep_embeddings if self.deep_embeddings is not None else self.combined_embeddings\n        \n        if method == 'similarity':\n            recs = self._similarity_recommendations(song_idx, n_recommendations, embeddings)\n        elif method == 'cluster':\n            recs = self._cluster_recommendations(song_idx, n_recommendations)\n        elif method == 'popularity':\n            recs = self._popularity_recommendations(song_idx, n_recommendations, embeddings)\n        elif method == 'hybrid':\n            recs = self._hybrid_recommendations(song_idx, n_recommendations, embeddings)\n        else:\n            raise ValueError(f\"Unknown method: {method}\")\n        \n        self.recommendation_cache[cache_key] = recs\n        return recs\n    \n    def _similarity_recommendations(self, song_idx, n_recs, embeddings):\n        if ANNOY_AVAILABLE and self.annoy_index:\n            similar_indices = self.annoy_index.get_nns_by_item(song_idx, n_recs + 1)[1:]\n        else:\n            distances, indices = self.nearest_neighbors.kneighbors(embeddings[song_idx].reshape(1, -1), n_neighbors=n_recs + 1)\n            similar_indices = indices[0][1:]\n        return self.df.iloc[similar_indices]\n    \n    def _cluster_recommendations(self, song_idx, n_recs):\n        song_cluster = self.df.iloc[song_idx]['kmeans_cluster']\n        cluster_songs = self.df[self.df['kmeans_cluster'] == song_cluster]\n        cluster_songs = cluster_songs[cluster_songs.index != song_idx]\n        \n        if len(cluster_songs) >= n_recs:\n            return cluster_songs.sample(n_recs, random_state=self.random_state)\n        return cluster_songs\n    \n    def _popularity_recommendations(self, song_idx, n_recs, embeddings):\n        if self.popularity_predictor is None:\n            return self._similarity_recommendations(song_idx, n_recs, embeddings)\n        \n        similar_songs = self._similarity_recommendations(song_idx, n_recs * 3, embeddings)\n        \n        # Use the same embeddings that were used to train the popularity predictor\n        prediction_embeddings = self.deep_embeddings if self.deep_embeddings is not None else self.combined_embeddings\n        similar_embeddings = prediction_embeddings[similar_songs.index]\n        \n        popularity_scores = self.popularity_predictor.predict(similar_embeddings)\n        \n        similar_songs = similar_songs.copy()\n        similar_songs['predicted_popularity'] = popularity_scores\n        return similar_songs.nlargest(n_recs, 'predicted_popularity')\n    \n    def _hybrid_recommendations(self, song_idx, n_recs, embeddings):\n        sim_recs = self._similarity_recommendations(song_idx, n_recs, embeddings)\n        cluster_recs = self._cluster_recommendations(song_idx, n_recs)\n        \n        all_recs = pd.concat([sim_recs, cluster_recs]).drop_duplicates()\n        \n        if self.popularity_predictor is not None and len(all_recs) > n_recs:\n            # Use the same embeddings that were used to train the popularity predictor\n            prediction_embeddings = self.deep_embeddings if self.deep_embeddings is not None else self.combined_embeddings\n            rec_embeddings = prediction_embeddings[all_recs.index]\n            \n            popularity_scores = self.popularity_predictor.predict(rec_embeddings)\n            all_recs = all_recs.copy()\n            all_recs['predicted_popularity'] = popularity_scores\n            all_recs = all_recs.nlargest(n_recs, 'predicted_popularity')\n        \n        return all_recs.head(n_recs)\n    \n    def create_visualization(self):\n        if not self.dimensionality_results:\n            print(\"Run dimensionality_reduction() first\")\n            return None\n        \n        df_sample = self.dimensionality_results['df_sample']\n        color_col = 'mood' if 'mood' in df_sample.columns else 'kmeans_cluster'\n        \n        fig = make_subplots(rows=2, cols=2, subplot_titles=['PCA', 'UMAP', 't-SNE', 'Clusters'])\n        \n        # PCA\n        fig.add_trace(go.Scatter(x=self.dimensionality_results['pca'][:, 0],\n                                y=self.dimensionality_results['pca'][:, 1],\n                                mode='markers', marker=dict(color=df_sample[color_col].astype(str), size=4),\n                                name='PCA'), row=1, col=1)\n        \n        # UMAP\n        fig.add_trace(go.Scatter(x=self.dimensionality_results['umap'][:, 0],\n                                y=self.dimensionality_results['umap'][:, 1],\n                                mode='markers', marker=dict(color=df_sample[color_col].astype(str), size=4),\n                                name='UMAP'), row=1, col=2)\n        \n        # t-SNE\n        fig.add_trace(go.Scatter(x=self.dimensionality_results['tsne'][:, 0],\n                                y=self.dimensionality_results['tsne'][:, 1],\n                                mode='markers', marker=dict(color=df_sample[color_col].astype(str), size=4),\n                                name='t-SNE'), row=2, col=1)\n        \n        # Clusters\n        if 'kmeans_cluster' in df_sample.columns:\n            fig.add_trace(go.Scatter(x=self.dimensionality_results['pca'][:, 0],\n                                    y=self.dimensionality_results['pca'][:, 1],\n                                    mode='markers', marker=dict(color=df_sample['kmeans_cluster'], size=4),\n                                    name='Clusters'), row=2, col=2)\n        \n        fig.update_layout(title=\"Music Recommendation System Visualization\", height=800, showlegend=False)\n        return fig\n    \n    def analyze_song(self, song_idx):\n        if song_idx >= len(self.df):\n            raise ValueError(f\"Song index {song_idx} out of range\")\n        \n        song = self.df.iloc[song_idx]\n        print(f\"\\n=== Song Analysis (Index: {song_idx}) ===\")\n        \n        if 'name' in song.index:\n            print(f\"Song: {song['name']}\")\n        if 'artists' in song.index:\n            print(f\"Artist: {song['artists']}\")\n        \n        print(f\"\\nAudio Features:\")\n        for feature in self.audio_cols:\n            if feature in song.index:\n                print(f\"  {feature}: {song[feature]:.3f}\")\n        \n        if 'mood' in song.index:\n            print(f\"\\nMood: {song['mood']}\")\n        if 'kmeans_cluster' in song.index:\n            print(f\"Cluster: {song['kmeans_cluster']}\")\n        if 'popularity_score' in song.index:\n            print(f\"Popularity Score: {song['popularity_score']:.3f}\")\n    \n    def get_feature_importance(self):\n        if self.popularity_predictor is None:\n            return None\n        \n        # Check which embeddings were used for training\n        if self.deep_embeddings is not None:\n            # For deep embeddings, create generic feature names\n            feature_names = [f'deep_feature_{i}' for i in range(self.deep_embeddings.shape[1])]\n        else:\n            # For combined embeddings, use original feature names\n            feature_names = (self.audio_cols + \n                            ['energy_valence_ratio', 'danceability_energy_product',\n                             'acoustic_electronic_balance', 'vocal_prominence', 'audio_complexity'] +\n                            (['explicit'] if 'explicit' in self.df.columns else []) +\n                            list(self.metadata_features.columns))\n        \n        importances = self.popularity_predictor.feature_importances_\n        \n        return pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n    def setup_infinite_system(self):\n        \"\"\"Setup the infinite recommendation system\"\"\"\n        self.user_manager = UserProfileManager(recommender=self)\n        self.api = InfiniteRecommendationAPI(self, self.user_manager)\n        self.monitor = PerformanceMonitor()\n        print(\"Infinite recommendation system initialized\")    \n    # ADD this method to your AdvancedMusicRecommender class\n    def quick_retrain(self, user_feedback_batch):\n        \"\"\"Quick model update based on recent feedback\"\"\"\n        if not user_feedback_batch:\n            return\n        \n        # Update popularity scores based on feedback\n        feedback_df = pd.DataFrame(user_feedback_batch)\n        song_feedback = feedback_df.groupby('song_idx')['feedback_value'].mean()\n        \n        for song_idx, avg_feedback in song_feedback.items():\n            if song_idx < len(self.df):\n                # Adjust popularity score\n                current_pop = self.df.iloc[song_idx]['popularity_score']\n                self.df.iloc[song_idx, self.df.columns.get_loc('popularity_score')] = \\\n                    current_pop * 0.9 + avg_feedback * 0.1\n        \n        print(f\"Updated {len(song_feedback)} songs based on feedback\")\n        \nclass UserProfileManager:\n    def __init__(self, db_path=\"user_profiles.db\", recommender=None):\n            self.db_path = db_path\n            self.recommender = recommender  # Store reference to recommender\n            self.user_profiles = {}\n            self.user_embeddings = {}\n            self._init_db()    \n    def _init_db(self):\n        with sqlite3.connect(self.db_path) as conn:\n            conn.execute('''CREATE TABLE IF NOT EXISTS user_profiles\n                          (user_id TEXT PRIMARY KEY, preferences TEXT, \n                           listening_history TEXT, created_at REAL, last_updated REAL)''')\n            conn.execute('''CREATE TABLE IF NOT EXISTS user_feedback\n                          (user_id TEXT, song_idx INTEGER, feedback_type TEXT,\n                           feedback_value REAL, timestamp REAL, context TEXT)''')\n    def set_recommender(self, recommender):\n        \"\"\"Set the recommender reference after initialization\"\"\"\n        self.recommender = recommender\n    \n    def create_user_profile(self, user_id, initial_preferences=None):\n        profile = {\n            'preferences': initial_preferences or {},\n            'listening_history': deque(maxlen=1000),  # Keep last 1000 interactions\n            'feedback_scores': defaultdict(float),\n            'created_at': time.time()\n        }\n        self.user_profiles[user_id] = profile\n        return profile\n    \n    def update_user_profile(self, user_id, song_idx, feedback_type, feedback_value=1.0, context=None):\n        if user_id not in self.user_profiles:\n            self.create_user_profile(user_id)\n        \n        profile = self.user_profiles[user_id]\n        profile['listening_history'].append({\n            'song_idx': song_idx, 'feedback_type': feedback_type,\n            'feedback_value': feedback_value, 'timestamp': time.time()\n        })\n        \n        # Update feedback scores for features\n        if hasattr(self, 'recommender') and song_idx < len(self.recommender.df):\n            song_features = self.recommender.df.iloc[song_idx][self.recommender.audio_cols]\n            for feature, value in song_features.items():\n                profile['feedback_scores'][feature] += feedback_value * value * 0.1\n    \n    def get_user_preferences(self, user_id):\n        return self.user_profiles.get(user_id, {}).get('feedback_scores', {})\n\nclass InfiniteRecommendationAPI:\n    def __init__(self, recommender, user_manager):\n        self.recommender = recommender\n        self.user_manager = user_manager\n        self.cache = {}\n        self.cache_expiry = 1800  # 30 minutes\n        \n    def get_infinite_feed(self, user_id, page_size=20, offset=0, context=None):\n        cache_key = f\"{user_id}_{page_size}_{offset}_{hash(str(context))}\"\n        \n        # Check cache\n        if cache_key in self.cache:\n            cached_data = self.cache[cache_key]\n            if time.time() - cached_data['timestamp'] < self.cache_expiry:\n                return cached_data['recommendations']\n        \n        # Generate recommendations\n        user_prefs = self.user_manager.get_user_preferences(user_id)\n        recs = self._generate_personalized_feed(user_id, user_prefs, page_size, offset, context)\n        \n        # Cache results\n        self.cache[cache_key] = {\n            'recommendations': recs,\n            'timestamp': time.time()\n        }\n        \n        return recs\n    \n    def _generate_personalized_feed(self, user_id, user_prefs, page_size, offset, context):\n        # Get base recommendations\n        available_songs = list(range(len(self.recommender.df)))\n        \n        # Remove already seen songs\n        if user_id in self.user_manager.user_profiles:\n            seen_songs = {item['song_idx'] for item in self.user_manager.user_profiles[user_id]['listening_history']}\n            available_songs = [idx for idx in available_songs if idx not in seen_songs]\n        \n        # Apply context filtering\n        if context:\n            available_songs = self._apply_context_filter(available_songs, context)\n        \n        # Score songs based on user preferences\n        if user_prefs:\n            scored_songs = self._score_songs_by_preferences(available_songs, user_prefs)\n        else:\n            # Cold start: use popularity or random\n            scored_songs = [(idx, np.random.random()) for idx in available_songs]\n        \n        # Sort and paginate\n        scored_songs.sort(key=lambda x: x[1], reverse=True)\n        paginated_songs = scored_songs[offset:offset + page_size]\n        \n        # Return song data\n        return [self.recommender.df.iloc[song_idx].to_dict() for song_idx, _ in paginated_songs]\n    \n    def _apply_context_filter(self, song_indices, context):\n        df = self.recommender.df\n        filtered = song_indices\n        \n        if context.get('mood') == 'energetic':\n            filtered = [idx for idx in filtered if df.iloc[idx]['energy'] > 0.6]\n        elif context.get('mood') == 'calm':\n            filtered = [idx for idx in filtered if df.iloc[idx]['energy'] < 0.4]\n        elif context.get('mood') == 'workout':\n            filtered = [idx for idx in filtered if df.iloc[idx]['energy'] > 0.7 and df.iloc[idx]['tempo'] > 120]\n        \n        return filtered if filtered else song_indices[:100]  # Fallback\n    \n    def _score_songs_by_preferences(self, song_indices, user_prefs):\n        scored = []\n        df = self.recommender.df\n        \n        for idx in song_indices:\n            song = df.iloc[idx]\n            score = 0\n            \n            # Score based on user preferences\n            for feature, pref_value in user_prefs.items():\n                if feature in song.index:\n                    feature_score = pref_value * song[feature]\n                    score += feature_score\n            \n            # Add some randomness for diversity\n            score += np.random.random() * 0.1\n            scored.append((idx, score))\n        \n        return scored\n    \n    def add_user_feedback(self, user_id, song_idx, feedback_type, feedback_value=1.0, context=None):\n        \"\"\"Add user feedback and clear relevant cache\"\"\"\n        self.user_manager.update_user_profile(user_id, song_idx, feedback_type, feedback_value, context)\n        \n        # Clear user's cache\n        keys_to_remove = [key for key in self.cache.keys() if key.startswith(f\"{user_id}_\")]\n        for key in keys_to_remove:\n            del self.cache[key]\n\nclass PerformanceMonitor:\n    def __init__(self, window_size=1000):\n        self.metrics = defaultdict(deque)\n        self.window_size = window_size\n        \n    def track_interaction(self, user_id, song_idx, interaction_type, value=1.0):\n        self.metrics['interactions'].append({\n            'user_id': user_id, 'song_idx': song_idx,\n            'type': interaction_type, 'value': value,\n            'timestamp': time.time()\n        })\n        \n        # Keep only recent interactions\n        if len(self.metrics['interactions']) > self.window_size:\n            self.metrics['interactions'].popleft()\n    \n    def get_engagement_rate(self, time_window=3600):  # Last hour\n        current_time = time.time()\n        recent_interactions = [\n            interaction for interaction in self.metrics['interactions']\n            if current_time - interaction['timestamp'] < time_window\n        ]\n        \n        if not recent_interactions:\n            return 0.0\n        \n        plays = sum(1 for i in recent_interactions if i['type'] == 'play')\n        return plays / len(recent_interactions)\n    \n    def should_retrain(self):\n        return self.get_engagement_rate() < 0.3  # Retrain if engagement drops below 30%\n\n\nclass MusicGenreClassifier:\n    def __init__(self, recommender):\n        self.recommender = recommender\n        self.genre_classifier = None\n        self.genre_encoder = LabelEncoder()\n    \n    def train_genre_classifier(self, genre_column='genre'):\n        if genre_column not in self.recommender.df.columns:\n            print(f\"Creating synthetic genres...\")\n            self._create_synthetic_genres()\n            genre_column = 'synthetic_genre'\n        \n        X = self.recommender.combined_embeddings\n        y = self.genre_encoder.fit_transform(self.recommender.df[genre_column])\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n        \n        self.genre_classifier = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n        self.genre_classifier.fit(X_train, y_train)\n        \n        y_pred = self.genre_classifier.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        \n        print(f\"Genre Classification Accuracy: {accuracy:.3f}\")\n        return accuracy\n    \n    def _create_synthetic_genres(self):\n        df = self.recommender.df\n        conditions = [\n            (df['energy'] > 0.7) & (df['valence'] > 0.6) & (df['danceability'] > 0.6),\n            (df['energy'] > 0.8) & (df['loudness'] > -5) & (df['tempo'] > 120),\n            (df['acousticness'] > 0.7) & (df['energy'] < 0.4),\n            (df['danceability'] > 0.8) & (df['energy'] > 0.6) & (df['tempo'] > 120),\n            (df['instrumentalness'] > 0.5) & (df['acousticness'] > 0.3),\n            (df['valence'] < 0.4) & (df['energy'] < 0.5),\n            (df['speechiness'] > 0.3) & (df['energy'] > 0.5),\n            (df['acousticness'] > 0.5) & (df['valence'] > 0.5),\n        ]\n        choices = ['Pop', 'Rock', 'Folk', 'Electronic', 'Instrumental', 'Ambient', 'Hip-Hop', 'Country']\n        self.recommender.df['synthetic_genre'] = np.select(conditions, choices, default='Other')\n    \n    def predict_genre(self, song_idx):\n        if self.genre_classifier is None:\n            return None\n        \n        song_embedding = self.recommender.combined_embeddings[song_idx].reshape(1, -1)\n        genre_pred = self.genre_classifier.predict(song_embedding)[0]\n        genre_proba = self.genre_classifier.predict_proba(song_embedding)[0]\n        \n        top_indices = np.argsort(genre_proba)[-3:][::-1]\n        top_genres = [(self.genre_encoder.classes_[i], genre_proba[i]) for i in top_indices]\n        \n        return {\n            'predicted_genre': self.genre_encoder.classes_[genre_pred],\n            'confidence': genre_proba[genre_pred],\n            'top_3_predictions': top_genres\n        }\n\n# Demo function\ndef demo_infinite_music_recommender(df=None):\n    print(\"=== Infinite Feed Music Recommendation System ===\\n\")\n    \n    # Create or load data\n    if df is None:\n        print(\"Creating optimized synthetic dataset...\")\n        np.random.seed(42)\n        n_songs = 3000  # Reduced for faster processing\n        \n        df = pd.DataFrame({\n            'danceability': np.random.beta(2, 2, n_songs),\n            'energy': np.random.beta(2, 2, n_songs),\n            'loudness': np.random.normal(-8, 4, n_songs),\n            'speechiness': np.random.exponential(0.1, n_songs),\n            'acousticness': np.random.beta(1, 3, n_songs),\n            'instrumentalness': np.random.exponential(0.2, n_songs),\n            'liveness': np.random.beta(1, 5, n_songs),\n            'valence': np.random.beta(2, 2, n_songs),\n            'tempo': np.random.normal(120, 30, n_songs),\n            'duration_ms': np.random.normal(210000, 60000, n_songs),\n            'explicit': np.random.choice([0, 1], n_songs, p=[0.85, 0.15]),\n            'time_signature': np.random.choice([3, 4, 5], n_songs, p=[0.05, 0.9, 0.05]),\n            'name': [f'Song_{i:04d}' for i in range(n_songs)],\n            'artists': [f'Artist_{i//20:03d}' for i in range(n_songs)],\n            'popularity': np.random.randint(0, 100, n_songs)\n        })\n        \n        # Clip values\n        for col in ['speechiness', 'instrumentalness']:\n            df[col] = np.clip(df[col], 0, 1)\n        df['tempo'] = np.clip(df['tempo'], 50, 200)\n        df['duration_ms'] = np.clip(df['duration_ms'], 30000, 600000)\n        df['loudness'] = np.clip(df['loudness'], -30, 0)\n    \n    # Initialize system\n    print(\"Building optimized system...\")\n    recommender = AdvancedMusicRecommender(df, n_jobs=-1)\n    \n    # Fast system build\n    recommender.create_embeddings()\n    recommender.perform_clustering(n_clusters=8, sample_size=1500)  # Optimized clustering\n    recommender.dimensionality_reduction(n_samples=2000)  # Reduced sample\n    recommender.build_recommendation_system()\n    \n    # Setup infinite system\n    recommender.setup_infinite_system()\n    \n    print(\"=== System Ready for Infinite Feed ===\")\n    return recommender \n    \ndef demo_infinite_feed():\n    # Initialize system\n    recommender = demo_infinite_music_recommender()\n    \n    # Simulate users\n    users = ['user_1', 'user_2', 'user_3']\n    \n    print(\"\\n=== Infinite Feed Demo ===\")\n    for user in users:\n        print(f\"\\nFeed for {user}:\")\n        \n        # Get initial feed\n        feed = recommender.api.get_infinite_feed(user, page_size=5)\n        for i, song in enumerate(feed):\n            print(f\"  {i+1}. {song['name']} - Energy: {song['energy']:.2f}\")\n        \n        # Simulate user interaction\n        recommender.api.add_user_feedback(user, 0, 'play', 1.0)\n        recommender.api.add_user_feedback(user, 1, 'skip', -0.5)\n        \n        # Get next page (should be personalized)\n        next_feed = recommender.api.get_infinite_feed(user, page_size=3, offset=5)\n        print(f\"  Next 3 recommendations for {user}:\")\n        for i, song in enumerate(next_feed):\n            print(f\"    {i+1}. {song['name']} - Valence: {song['valence']:.2f}\")\n\n# Run demo\nif __name__ == \"__main__\":\n    try:\n        # Try to load your dataset\n        df = pd.read_csv('/kaggle/input/spotify-12m-songs/tracks_features.csv')  # Replace with your actual dataset path\n        print(f\"Loaded dataset with {len(df)} songs\")\n        recommender = demo_infinite_music_recommender(df)\n        \n        # Initialize genre classifier\n        genre_classifier = MusicGenreClassifier(recommender)\n        genre_classifier.train_genre_classifier()\n        \n    except FileNotFoundError:\n        print(\"Dataset file not found. Running with synthetic data...\")\n        recommender = demo_infinite_music_recommender()\n        \n        # Initialize genre classifier\n        genre_classifier = MusicGenreClassifier(recommender)\n        genre_classifier.train_genre_classifier()\n        \n    except Exception as e:\n        print(f\"Error loading dataset: {e}\")\n        print(\"Running with synthetic data...\")\n        recommender = demo_infinite_music_recommender()\n        \n        # Initialize genre classifier\n        genre_classifier = MusicGenreClassifier(recommender)\n        genre_classifier.train_genre_classifier()\n    \n    # Run the infinite feed demo\n    demo_infinite_feed()\n    \n    print(\"\\n=== Demo Complete ===\")\n    print(\"You can now use the recommender and genre_classifier objects for further analysis.\")\n    print(\"\\nExample usage:\")\n    print(\"- recommender.get_recommendations(song_index, n_recommendations=10, method='hybrid')\")\n    print(\"- recommender.analyze_song(song_index)\")\n    print(\"- genre_classifier.predict_genre(song_index)\")\n    print(\"- recommender.create_visualization()\")\n    print(\"- demo_infinite_feed()  # Run infinite feed simulation\")\n    \n    # Additional examples\n    print(\"\\n=== Quick Examples ===\")\n    try:\n        # Analyze a random song\n        random_idx = np.random.randint(0, len(recommender.df))\n        print(f\"\\nAnalyzing random song (index {random_idx}):\")\n        recommender.analyze_song(random_idx)\n        \n        # Get recommendations\n        print(f\"\\nRecommendations for song {random_idx}:\")\n        recs = recommender.get_recommendations(random_idx, n_recommendations=5)\n        for i, (idx, row) in enumerate(recs.iterrows()):\n            print(f\"  {i+1}. {row.get('name', f'Song_{idx}')} - Energy: {row['energy']:.2f}, Valence: {row['valence']:.2f}\")\n        \n        # Show feature importance\n        print(\"\\nTop 10 Most Important Features for Popularity Prediction:\")\n        importance_df = recommender.get_feature_importance()\n        if importance_df is not None:\n            print(importance_df.head(10).to_string(index=False))\n        \n        # Genre prediction example\n        genre_pred = genre_classifier.predict_genre(random_idx)\n        if genre_pred:\n            print(f\"\\nGenre prediction for song {random_idx}:\")\n            print(f\"  Predicted: {genre_pred['predicted_genre']} (confidence: {genre_pred['confidence']:.2f})\")\n            print(\"  Top 3 predictions:\")\n            for genre, prob in genre_pred['top_3_predictions']:\n                print(f\"    {genre}: {prob:.3f}\")\n                \n    except Exception as e:\n        print(f\"Error in examples: {e}\")\n        \n    print(\"\\n=== System Information ===\")\n    print(f\"Dataset size: {len(recommender.df)} songs\")\n    print(f\"Embedding dimensions: {recommender.combined_embeddings.shape[1] if recommender.combined_embeddings is not None else 'N/A'}\")\n    print(f\"Deep embedding dimensions: {recommender.deep_embeddings.shape[1] if recommender.deep_embeddings is not None else 'N/A'}\")\n    print(f\"Number of clusters: {len(recommender.df['kmeans_cluster'].unique()) if 'kmeans_cluster' in recommender.df.columns else 'N/A'}\")\n    print(f\"TensorFlow available: {TF_AVAILABLE}\")\n    print(f\"Annoy available: {ANNOY_AVAILABLE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T19:29:41.931204Z","iopub.execute_input":"2025-06-22T19:29:41.931903Z","iopub.status.idle":"2025-06-22T19:56:50.276982Z","shell.execute_reply.started":"2025-06-22T19:29:41.931875Z","shell.execute_reply":"2025-06-22T19:56:50.276314Z"}},"outputs":[{"name":"stderr","text":"2025-06-22 19:30:01.741495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750620602.224196      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750620602.348070      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 2 GPU(s)\nGPU memory growth enabled\nMixed precision enabled\nTensorFlow configured successfully\nLoaded dataset with 1204025 songs\n=== Infinite Feed Music Recommendation System ===\n\nBuilding optimized system...\nPreprocessing data...\nDataset shape: (1204025, 33)\nCreating embeddings...\nCombined embeddings shape: (1204025, 35)\nCreating deep embeddings with GPU optimization...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750620645.270972      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1750620645.271708      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750620653.187093      99 service.cc:148] XLA service 0x7beb300298c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750620653.188413      99 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1750620653.188435      99 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1750620653.889289      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  56/7526\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 1.9254 - mae: 1.0402 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1750620658.355710      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - loss: 0.2064 - mae: 0.2762 - val_loss: 0.0708 - val_mae: 0.0792 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 0.0513 - mae: 0.1466 - val_loss: 0.0548 - val_mae: 0.0664 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 0.0452 - mae: 0.1363 - val_loss: 0.0262 - val_mae: 0.0615 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 0.0429 - mae: 0.1325 - val_loss: 0.2981 - val_mae: 0.0563 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 0.0415 - mae: 0.1303 - val_loss: 0.0189 - val_mae: 0.0579 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 0.0405 - mae: 0.1293 - val_loss: 0.1293 - val_mae: 0.0595 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1282 - val_loss: 0.1666 - val_mae: 0.0552 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1271 - val_loss: 0.3590 - val_mae: 0.0623 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0387 - mae: 0.1264 - val_loss: 0.1918 - val_mae: 0.0658 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1255 - val_loss: 0.3591 - val_mae: 0.0549 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.1252 - val_loss: 0.3107 - val_mae: 0.0564 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0378 - mae: 0.1247 - val_loss: 0.0552 - val_mae: 0.0519 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.1233 - val_loss: 0.2439 - val_mae: 0.0504 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1227 - val_loss: 0.4756 - val_mae: 0.0517 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0363 - mae: 0.1226 - val_loss: 0.6518 - val_mae: 0.0522 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1222 - val_loss: 0.1974 - val_mae: 0.0524 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1221 - val_loss: 0.3242 - val_mae: 0.0479 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0359 - mae: 0.1221 - val_loss: 1.2424 - val_mae: 0.0545 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0357 - mae: 0.1217 - val_loss: 0.5416 - val_mae: 0.0504 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m7526/7526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0352 - mae: 0.1208 - val_loss: 0.1495 - val_mae: 0.0479 - learning_rate: 2.5000e-04\n\u001b[1m9407/9407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\nModel saved: models/autoencoder/autoencoder_1750621210.h5\nModel saved: models/encoder/encoder_1750621210.h5\nDeep embeddings shape: (1204025, 17)\nPerforming optimized clustering...\nUsing sample of 1500 songs for clustering\nK-means Silhouette (sample): 0.115\n\nCluster Analysis:\n\nCluster 0 (189432 songs):\n  Avg energy: 0.090\n  Avg valence: 0.187\n  Avg danceability: 0.313\n  Avg acousticness: 0.909\n\nCluster 1 (327506 songs):\n  Avg energy: 0.801\n  Avg valence: 0.581\n  Avg danceability: 0.562\n  Avg acousticness: 0.131\n\nCluster 2 (70632 songs):\n  Avg energy: 0.698\n  Avg valence: 0.451\n  Avg danceability: 0.447\n  Avg acousticness: 0.292\n\nCluster 3 (141686 songs):\n  Avg energy: 0.712\n  Avg valence: 0.394\n  Avg danceability: 0.497\n  Avg acousticness: 0.183\n\nCluster 4 (268901 songs):\n  Avg energy: 0.450\n  Avg valence: 0.533\n  Avg danceability: 0.561\n  Avg acousticness: 0.510\n\nCluster 5 (154358 songs):\n  Avg energy: 0.238\n  Avg valence: 0.208\n  Avg danceability: 0.416\n  Avg acousticness: 0.762\n\nCluster 6 (50670 songs):\n  Avg energy: 0.505\n  Avg valence: 0.525\n  Avg danceability: 0.654\n  Avg acousticness: 0.414\n\nCluster 7 (840 songs):\n  Avg energy: 0.778\n  Avg valence: 0.000\n  Avg danceability: 0.070\n  Avg acousticness: 0.429\nPerforming dimensionality reduction with parallel processing...\nModel saved: models/pca_model/pca_model_1750621228.joblib\nModel saved: models/umap_model/umap_model_1750621228.joblib\nPCA explained variance: 0.457\nBuilding recommendation system...\nTraining popularity predictor with optimization...\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  2.6min\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 11.5min\n[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 12.0min finished\n","output_type":"stream"},{"name":"stdout","text":"Model saved: models/popularity_predictor/popularity_predictor_1750621963.joblib\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.8s\n[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    3.0s finished\n","output_type":"stream"},{"name":"stdout","text":"Popularity Predictor - MSE: 0.001, R²: 0.977\nInfinite recommendation system initialized\n=== System Ready for Infinite Feed ===\nCreating synthetic genres...\nGenre Classification Accuracy: 1.000\n=== Infinite Feed Music Recommendation System ===\n\nCreating optimized synthetic dataset...\nBuilding optimized system...\nPreprocessing data...\nDataset shape: (3000, 24)\nCreating embeddings...\nCombined embeddings shape: (3000, 32)\nCreating deep embeddings with GPU optimization...\nEpoch 1/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 304ms/step - loss: 2.5246 - mae: 1.2156 - val_loss: 0.5371 - val_mae: 0.4935 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4772 - mae: 0.9272 - val_loss: 0.5093 - val_mae: 0.4877 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1652 - mae: 0.8202 - val_loss: 0.4845 - val_mae: 0.4821 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9434 - mae: 0.7352 - val_loss: 0.4615 - val_mae: 0.4744 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8268 - mae: 0.6854 - val_loss: 0.4367 - val_mae: 0.4665 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7300 - mae: 0.6448 - val_loss: 0.4132 - val_mae: 0.4524 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6908 - mae: 0.6096 - val_loss: 0.3905 - val_mae: 0.4414 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5893 - mae: 0.5790 - val_loss: 0.3640 - val_mae: 0.4299 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5451 - mae: 0.5554 - val_loss: 0.3399 - val_mae: 0.4166 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4858 - mae: 0.5268 - val_loss: 0.3138 - val_mae: 0.4035 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4547 - mae: 0.5075 - val_loss: 0.2848 - val_mae: 0.3870 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4333 - mae: 0.4887 - val_loss: 0.2649 - val_mae: 0.3744 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3825 - mae: 0.4681 - val_loss: 0.2383 - val_mae: 0.3578 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3589 - mae: 0.4528 - val_loss: 0.2217 - val_mae: 0.3456 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3331 - mae: 0.4374 - val_loss: 0.2029 - val_mae: 0.3324 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3196 - mae: 0.4251 - val_loss: 0.1861 - val_mae: 0.3203 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3086 - mae: 0.4126 - val_loss: 0.1723 - val_mae: 0.3080 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2875 - mae: 0.4011 - val_loss: 0.1612 - val_mae: 0.2985 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2683 - mae: 0.3902 - val_loss: 0.1495 - val_mae: 0.2889 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2532 - mae: 0.3767 - val_loss: 0.1410 - val_mae: 0.2800 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2439 - mae: 0.3703 - val_loss: 0.1356 - val_mae: 0.2738 - learning_rate: 0.0010\nEpoch 22/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2364 - mae: 0.3618 - val_loss: 0.1288 - val_mae: 0.2680 - learning_rate: 0.0010\nEpoch 23/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2256 - mae: 0.3532 - val_loss: 0.1243 - val_mae: 0.2625 - learning_rate: 0.0010\nEpoch 24/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2173 - mae: 0.3473 - val_loss: 0.1197 - val_mae: 0.2575 - learning_rate: 0.0010\nEpoch 25/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2088 - mae: 0.3357 - val_loss: 0.1158 - val_mae: 0.2534 - learning_rate: 0.0010\nEpoch 26/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2017 - mae: 0.3333 - val_loss: 0.1119 - val_mae: 0.2491 - learning_rate: 0.0010\nEpoch 27/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1997 - mae: 0.3287 - val_loss: 0.1092 - val_mae: 0.2463 - learning_rate: 0.0010\nEpoch 28/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1926 - mae: 0.3250 - val_loss: 0.1062 - val_mae: 0.2425 - learning_rate: 0.0010\nEpoch 29/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2074 - mae: 0.3222 - val_loss: 0.1043 - val_mae: 0.2396 - learning_rate: 0.0010\nEpoch 30/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1768 - mae: 0.3123 - val_loss: 0.1009 - val_mae: 0.2356 - learning_rate: 0.0010\nEpoch 31/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1796 - mae: 0.3122 - val_loss: 0.0985 - val_mae: 0.2327 - learning_rate: 0.0010\nEpoch 32/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1712 - mae: 0.3069 - val_loss: 0.0966 - val_mae: 0.2298 - learning_rate: 0.0010\nEpoch 33/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1684 - mae: 0.3022 - val_loss: 0.0954 - val_mae: 0.2283 - learning_rate: 0.0010\nEpoch 34/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1648 - mae: 0.2999 - val_loss: 0.0920 - val_mae: 0.2239 - learning_rate: 0.0010\nEpoch 35/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1660 - mae: 0.2996 - val_loss: 0.0902 - val_mae: 0.2220 - learning_rate: 0.0010\nEpoch 36/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1600 - mae: 0.2954 - val_loss: 0.0892 - val_mae: 0.2201 - learning_rate: 0.0010\nEpoch 37/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1601 - mae: 0.2925 - val_loss: 0.0865 - val_mae: 0.2164 - learning_rate: 0.0010\nEpoch 38/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1544 - mae: 0.2909 - val_loss: 0.0856 - val_mae: 0.2156 - learning_rate: 0.0010\nEpoch 39/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1545 - mae: 0.2903 - val_loss: 0.0835 - val_mae: 0.2128 - learning_rate: 0.0010\nEpoch 40/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1533 - mae: 0.2874 - val_loss: 0.0825 - val_mae: 0.2117 - learning_rate: 0.0010\nEpoch 41/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1564 - mae: 0.2874 - val_loss: 0.0811 - val_mae: 0.2091 - learning_rate: 0.0010\nEpoch 42/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1572 - mae: 0.2852 - val_loss: 0.0798 - val_mae: 0.2074 - learning_rate: 0.0010\nEpoch 43/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1538 - mae: 0.2847 - val_loss: 0.0783 - val_mae: 0.2052 - learning_rate: 0.0010\nEpoch 44/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1449 - mae: 0.2780 - val_loss: 0.0775 - val_mae: 0.2041 - learning_rate: 0.0010\nEpoch 45/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1466 - mae: 0.2797 - val_loss: 0.0769 - val_mae: 0.2034 - learning_rate: 0.0010\nEpoch 46/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1425 - mae: 0.2768 - val_loss: 0.0748 - val_mae: 0.2003 - learning_rate: 0.0010\nEpoch 47/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1428 - mae: 0.2750 - val_loss: 0.0743 - val_mae: 0.1993 - learning_rate: 0.0010\nEpoch 48/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1424 - mae: 0.2749 - val_loss: 0.0730 - val_mae: 0.1970 - learning_rate: 0.0010\nEpoch 49/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1401 - mae: 0.2736 - val_loss: 0.0724 - val_mae: 0.1964 - learning_rate: 0.0010\nEpoch 50/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1358 - mae: 0.2716 - val_loss: 0.0714 - val_mae: 0.1948 - learning_rate: 0.0010\nEpoch 51/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1406 - mae: 0.2700 - val_loss: 0.0703 - val_mae: 0.1926 - learning_rate: 0.0010\nEpoch 52/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1402 - mae: 0.2710 - val_loss: 0.0696 - val_mae: 0.1919 - learning_rate: 0.0010\nEpoch 53/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1375 - mae: 0.2692 - val_loss: 0.0683 - val_mae: 0.1896 - learning_rate: 0.0010\nEpoch 54/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1353 - mae: 0.2673 - val_loss: 0.0680 - val_mae: 0.1892 - learning_rate: 0.0010\nEpoch 55/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1378 - mae: 0.2705 - val_loss: 0.0675 - val_mae: 0.1891 - learning_rate: 0.0010\nEpoch 56/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1279 - mae: 0.2642 - val_loss: 0.0662 - val_mae: 0.1861 - learning_rate: 0.0010\nEpoch 57/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1357 - mae: 0.2674 - val_loss: 0.0662 - val_mae: 0.1864 - learning_rate: 0.0010\nEpoch 58/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1359 - mae: 0.2657 - val_loss: 0.0650 - val_mae: 0.1845 - learning_rate: 0.0010\nEpoch 59/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1305 - mae: 0.2646 - val_loss: 0.0647 - val_mae: 0.1840 - learning_rate: 0.0010\nEpoch 60/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1335 - mae: 0.2626 - val_loss: 0.0635 - val_mae: 0.1816 - learning_rate: 0.0010\nEpoch 61/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1259 - mae: 0.2614 - val_loss: 0.0626 - val_mae: 0.1797 - learning_rate: 0.0010\nEpoch 62/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1275 - mae: 0.2599 - val_loss: 0.0624 - val_mae: 0.1797 - learning_rate: 0.0010\nEpoch 63/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1286 - mae: 0.2601 - val_loss: 0.0614 - val_mae: 0.1784 - learning_rate: 0.0010\nEpoch 64/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1349 - mae: 0.2605 - val_loss: 0.0613 - val_mae: 0.1784 - learning_rate: 0.0010\nEpoch 65/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1291 - mae: 0.2585 - val_loss: 0.0607 - val_mae: 0.1773 - learning_rate: 0.0010\nEpoch 66/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1433 - mae: 0.2584 - val_loss: 0.0598 - val_mae: 0.1755 - learning_rate: 0.0010\nEpoch 67/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1197 - mae: 0.2545 - val_loss: 0.0589 - val_mae: 0.1735 - learning_rate: 0.0010\nEpoch 68/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1193 - mae: 0.2543 - val_loss: 0.0593 - val_mae: 0.1740 - learning_rate: 0.0010\nEpoch 69/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1192 - mae: 0.2546 - val_loss: 0.0583 - val_mae: 0.1729 - learning_rate: 0.0010\nEpoch 70/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1210 - mae: 0.2533 - val_loss: 0.0577 - val_mae: 0.1720 - learning_rate: 0.0010\nEpoch 71/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1177 - mae: 0.2536 - val_loss: 0.0577 - val_mae: 0.1722 - learning_rate: 0.0010\nEpoch 72/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1221 - mae: 0.2548 - val_loss: 0.0574 - val_mae: 0.1708 - learning_rate: 0.0010\nEpoch 73/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1268 - mae: 0.2542 - val_loss: 0.0567 - val_mae: 0.1698 - learning_rate: 0.0010\nEpoch 74/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1179 - mae: 0.2526 - val_loss: 0.0564 - val_mae: 0.1695 - learning_rate: 0.0010\nEpoch 75/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1183 - mae: 0.2520 - val_loss: 0.0555 - val_mae: 0.1679 - learning_rate: 0.0010\nEpoch 76/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1223 - mae: 0.2518 - val_loss: 0.0554 - val_mae: 0.1672 - learning_rate: 0.0010\nEpoch 77/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1160 - mae: 0.2486 - val_loss: 0.0548 - val_mae: 0.1665 - learning_rate: 0.0010\nEpoch 78/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1233 - mae: 0.2517 - val_loss: 0.0546 - val_mae: 0.1663 - learning_rate: 0.0010\nEpoch 79/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1156 - mae: 0.2493 - val_loss: 0.0547 - val_mae: 0.1667 - learning_rate: 0.0010\nEpoch 80/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1178 - mae: 0.2492 - val_loss: 0.0535 - val_mae: 0.1645 - learning_rate: 0.0010\nEpoch 81/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1145 - mae: 0.2480 - val_loss: 0.0528 - val_mae: 0.1628 - learning_rate: 0.0010\nEpoch 82/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1177 - mae: 0.2480 - val_loss: 0.0528 - val_mae: 0.1627 - learning_rate: 0.0010\nEpoch 83/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1124 - mae: 0.2473 - val_loss: 0.0525 - val_mae: 0.1624 - learning_rate: 0.0010\nEpoch 84/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1186 - mae: 0.2465 - val_loss: 0.0526 - val_mae: 0.1619 - learning_rate: 0.0010\nEpoch 85/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1156 - mae: 0.2451 - val_loss: 0.0519 - val_mae: 0.1615 - learning_rate: 0.0010\nEpoch 86/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1260 - mae: 0.2474 - val_loss: 0.0519 - val_mae: 0.1618 - learning_rate: 0.0010\nEpoch 87/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1196 - mae: 0.2447 - val_loss: 0.0511 - val_mae: 0.1601 - learning_rate: 0.0010\nEpoch 88/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1134 - mae: 0.2432 - val_loss: 0.0513 - val_mae: 0.1601 - learning_rate: 0.0010\nEpoch 89/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1117 - mae: 0.2430 - val_loss: 0.0500 - val_mae: 0.1583 - learning_rate: 0.0010\nEpoch 90/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1098 - mae: 0.2420 - val_loss: 0.0501 - val_mae: 0.1581 - learning_rate: 0.0010\nEpoch 91/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1099 - mae: 0.2407 - val_loss: 0.0491 - val_mae: 0.1558 - learning_rate: 0.0010\nEpoch 92/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1064 - mae: 0.2398 - val_loss: 0.0489 - val_mae: 0.1559 - learning_rate: 0.0010\nEpoch 93/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1090 - mae: 0.2400 - val_loss: 0.0480 - val_mae: 0.1537 - learning_rate: 0.0010\nEpoch 94/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1103 - mae: 0.2395 - val_loss: 0.0480 - val_mae: 0.1538 - learning_rate: 0.0010\nEpoch 95/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1115 - mae: 0.2406 - val_loss: 0.0480 - val_mae: 0.1543 - learning_rate: 0.0010\nEpoch 96/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1087 - mae: 0.2385 - val_loss: 0.0475 - val_mae: 0.1532 - learning_rate: 0.0010\nEpoch 97/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1082 - mae: 0.2400 - val_loss: 0.0463 - val_mae: 0.1509 - learning_rate: 0.0010\nEpoch 98/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1048 - mae: 0.2354 - val_loss: 0.0471 - val_mae: 0.1522 - learning_rate: 0.0010\nEpoch 99/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1108 - mae: 0.2407 - val_loss: 0.0461 - val_mae: 0.1508 - learning_rate: 0.0010\nEpoch 100/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1149 - mae: 0.2386 - val_loss: 0.0466 - val_mae: 0.1513 - learning_rate: 0.0010\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\nModel saved: models/autoencoder/autoencoder_1750622195.h5\nModel saved: models/encoder/encoder_1750622195.h5\nDeep embeddings shape: (3000, 16)\nPerforming optimized clustering...\nUsing sample of 1500 songs for clustering\nK-means Silhouette (sample): 0.070\n\nCluster Analysis:\n\nCluster 0 (323 songs):\n  Avg energy: 0.440\n  Avg valence: 0.582\n  Avg danceability: 0.450\n  Avg acousticness: 0.238\n\nCluster 1 (341 songs):\n  Avg energy: 0.359\n  Avg valence: 0.492\n  Avg danceability: 0.562\n  Avg acousticness: 0.539\n\nCluster 2 (380 songs):\n  Avg energy: 0.438\n  Avg valence: 0.555\n  Avg danceability: 0.570\n  Avg acousticness: 0.186\n\nCluster 3 (310 songs):\n  Avg energy: 0.703\n  Avg valence: 0.198\n  Avg danceability: 0.594\n  Avg acousticness: 0.254\n\nCluster 4 (189 songs):\n  Avg energy: 0.502\n  Avg valence: 0.551\n  Avg danceability: 0.641\n  Avg acousticness: 0.341\n\nCluster 5 (379 songs):\n  Avg energy: 0.689\n  Avg valence: 0.647\n  Avg danceability: 0.679\n  Avg acousticness: 0.208\n\nCluster 6 (359 songs):\n  Avg energy: 0.376\n  Avg valence: 0.458\n  Avg danceability: 0.450\n  Avg acousticness: 0.225\n\nCluster 7 (719 songs):\n  Avg energy: 0.532\n  Avg valence: 0.488\n  Avg danceability: 0.342\n  Avg acousticness: 0.180\nPerforming dimensionality reduction with parallel processing...\nModel saved: models/pca_model/pca_model_1750622207.joblib\nModel saved: models/umap_model/umap_model_1750622207.joblib\nPCA explained variance: 0.307\nBuilding recommendation system...\nTraining popularity predictor with optimization...\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    1.6s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n","output_type":"stream"},{"name":"stdout","text":"Model saved: models/popularity_predictor/popularity_predictor_1750622208.joblib\nPopularity Predictor - MSE: 845.649, R²: -0.037\nInfinite recommendation system initialized\n=== System Ready for Infinite Feed ===\n\n=== Infinite Feed Demo ===\n\nFeed for user_1:\n  1. Song_0349 - Energy: 0.65\n  2. Song_0186 - Energy: 0.29\n  3. Song_2147 - Energy: 0.43\n  4. Song_1937 - Energy: 0.52\n  5. Song_2423 - Energy: 0.23\n  Next 3 recommendations for user_1:\n    1. Song_1000 - Valence: 0.48\n    2. Song_1287 - Valence: 0.55\n    3. Song_0899 - Valence: 0.22\n\nFeed for user_2:\n  1. Song_2572 - Energy: 0.18\n  2. Song_2061 - Energy: 0.64\n  3. Song_2634 - Energy: 0.13\n  4. Song_0488 - Energy: 0.30\n  5. Song_2736 - Energy: 0.58\n  Next 3 recommendations for user_2:\n    1. Song_1000 - Valence: 0.48\n    2. Song_1287 - Valence: 0.55\n    3. Song_0899 - Valence: 0.22\n\nFeed for user_3:\n  1. Song_1373 - Energy: 0.69\n  2. Song_1007 - Energy: 0.62\n  3. Song_2007 - Energy: 0.70\n  4. Song_1266 - Energy: 0.64\n  5. Song_2429 - Energy: 0.64\n  Next 3 recommendations for user_3:\n    1. Song_1000 - Valence: 0.48\n    2. Song_1287 - Valence: 0.55\n    3. Song_0899 - Valence: 0.22\n\n=== Demo Complete ===\nYou can now use the recommender and genre_classifier objects for further analysis.\n\nExample usage:\n- recommender.get_recommendations(song_index, n_recommendations=10, method='hybrid')\n- recommender.analyze_song(song_index)\n- genre_classifier.predict_genre(song_index)\n- recommender.create_visualization()\n- demo_infinite_feed()  # Run infinite feed simulation\n\n=== Quick Examples ===\n\nAnalyzing random song (index 635757):\n\n=== Song Analysis (Index: 635757) ===\nSong: Lost In Love\nArtist: ['Jim Adkins']\n\nAudio Features:\n  danceability: 0.723\n  energy: 0.586\n  loudness: -8.568\n  speechiness: 0.025\n  acousticness: 0.746\n  instrumentalness: 0.838\n  liveness: 0.100\n  valence: 0.688\n  tempo: 93.088\n  duration_ms: 251480.000\n\nMood: happy_calm\nCluster: 3\nPopularity Score: 0.451\n\nRecommendations for song 635757:\n  1. Fair Game - Energy: 0.99, Valence: 0.96\n  2. Dooleys Set - Energy: 0.72, Valence: 0.94\n  3. Sexy Ankles - Energy: 0.86, Valence: 0.73\n  4. Valkyries' New Ride (Instrumental) - 2019 Remaster - Energy: 0.99, Valence: 0.35\n  5. Tryin' To Keep It Real - Energy: 0.58, Valence: 0.77\n\nTop 10 Most Important Features for Popularity Prediction:\n        feature  importance\ndeep_feature_14    0.782977\n deep_feature_5    0.118418\n deep_feature_4    0.051359\n deep_feature_6    0.012389\ndeep_feature_15    0.008145\ndeep_feature_10    0.007091\n deep_feature_9    0.003734\n deep_feature_8    0.003675\ndeep_feature_13    0.003375\n deep_feature_3    0.003162\n\nGenre prediction for song 635757:\n  Predicted: Instrumental (confidence: 1.00)\n  Top 3 predictions:\n    Instrumental: 0.997\n    Other: 0.003\n    Folk: 0.000\n\n=== System Information ===\nDataset size: 1204025 songs\nEmbedding dimensions: 35\nDeep embedding dimensions: 17\nNumber of clusters: 8\nTensorFlow available: True\nAnnoy available: True\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!zip -r output.zip /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:34:19.176962Z","iopub.execute_input":"2025-06-22T20:34:19.177258Z","iopub.status.idle":"2025-06-22T20:34:41.110792Z","shell.execute_reply.started":"2025-06-22T20:34:19.177237Z","shell.execute_reply":"2025-06-22T20:34:41.109870Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/best_autoencoder.h5 (deflated 14%)\n  adding: kaggle/working/user_profiles.db (deflated 98%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/models/ (stored 0%)\n  adding: kaggle/working/models/pca_model/ (stored 0%)\n  adding: kaggle/working/models/pca_model/pca_model_1750622207.joblib (deflated 19%)\n  adding: kaggle/working/models/pca_model/metadata.json (deflated 33%)\n  adding: kaggle/working/models/pca_model/pca_model_1750621228.joblib (deflated 19%)\n  adding: kaggle/working/models/umap_model/ (stored 0%)\n  adding: kaggle/working/models/umap_model/metadata.json (deflated 34%)\n  adding: kaggle/working/models/umap_model/umap_model_1750621228.joblib","output_type":"stream"},{"name":"stderr","text":"Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n","output_type":"stream"},{"name":"stdout","text":" (deflated 46%)\n  adding: kaggle/working/models/umap_model/umap_model_1750622207.joblib (deflated 43%)\n  adding: kaggle/working/models/popularity_predictor/ (stored 0%)\n  adding: kaggle/working/models/popularity_predictor/popularity_predictor_1750621963.joblib (deflated 63%)\n  adding: kaggle/working/models/popularity_predictor/popularity_predictor_1750622208.joblib (deflated 73%)\n  adding: kaggle/working/models/popularity_predictor/metadata.json (deflated 37%)\n  adding: kaggle/working/models/encoder/ (stored 0%)\n  adding: kaggle/working/models/encoder/metadata.json (deflated 30%)\n  adding: kaggle/working/models/encoder/encoder_1750622195.h5 (deflated 19%)\n  adding: kaggle/working/models/encoder/encoder_1750621210.h5 (deflated 18%)\n  adding: kaggle/working/models/autoencoder/ (stored 0%)\n  adding: kaggle/working/models/autoencoder/autoencoder_1750621210.h5 (deflated 13%)\n  adding: kaggle/working/models/autoencoder/autoencoder_1750622195.h5 (deflated 14%)\n  adding: kaggle/working/models/autoencoder/metadata.json (deflated 33%)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}